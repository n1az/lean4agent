# Example .env file for Lean4Agent
# Copy this to .env and fill in your values

# LLM Provider: 'ollama' or 'openai'
LLM_PROVIDER=ollama

# Ollama Configuration
OLLAMA_URL=http://localhost:11434
OLLAMA_MODEL=bfs-prover-v2:32b

# OpenAI Configuration (if using OpenAI)
# OPENAI_API_KEY=your-api-key-here
# OPENAI_MODEL=gpt-4

# OpenAI Base URL (optional - for OpenAI-compatible APIs like Groq, LMStudio)
# For Groq: https://api.groq.com/openai/v1
# For LMStudio: http://localhost:1234/v1
# OPENAI_BASE_URL=

# Lean Server (optional)
# LEAN_SERVER_URL=http://localhost:8080

# Agent Configuration
MAX_ITERATIONS=50
TEMPERATURE=0.7
TIMEOUT=30

# Add 'sorry' when max iterations reached without completing proof
USE_SORRY_ON_TIMEOUT=true
